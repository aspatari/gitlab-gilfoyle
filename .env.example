# ===========================================
# Gilfoyle AI Agent Configuration
# ===========================================
# Copy this file to .env and fill in your values
# cp .env.example .env

# -------------------------------------------
# Application Settings
# -------------------------------------------
APP_NAME=Gilfoyle
DEBUG=false
LOG_LEVEL=INFO
HOST=0.0.0.0
PORT=8000

# -------------------------------------------
# GitLab Configuration
# -------------------------------------------
# Your GitLab instance URL (no trailing slash)
GITLAB_URL=https://gitlab.your-domain.com

# Personal Access Token for the gilfoyle user
# Required scopes: api, read_repository, write_repository, read_user
# Generate at: GitLab → User Settings → Access Tokens
GITLAB_TOKEN=glpat-xxxxxxxxxxxxxxxxxxxx

# Webhook secret for validating incoming webhooks
# Generate with: openssl rand -hex 32
GITLAB_WEBHOOK_SECRET=your-webhook-secret-here

# GitLab user ID for the gilfoyle account
# Find at: Admin Area → Users → gilfoyle → User ID in URL
GILFOYLE_USER_ID=123

# Username for the gilfoyle account
GILFOYLE_USERNAME=gilfoyle

# -------------------------------------------
# Teamwork Configuration
# -------------------------------------------
# Teamwork instance URL
TEAMWORK_URL=https://projects.ebs-integrator.com

# Teamwork API key
# Generate at: Teamwork → Profile → Settings → API & Integrations
TEAMWORK_API_KEY=tkn.xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# -------------------------------------------
# LLM Configuration
# -------------------------------------------
# LLM provider: "anthropic" or "openai"
LLM_PROVIDER=anthropic

# Anthropic API key (required if LLM_PROVIDER=anthropic)
# Generate at: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-api03-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# OpenAI API key (required if LLM_PROVIDER=openai)
# Generate at: https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Model to use for code reviews
# Recommended: claude-sonnet-4-20250514 (Anthropic) or gpt-4o (OpenAI)
LLM_MODEL=claude-sonnet-4-20250514

# Maximum tokens for LLM response
LLM_MAX_TOKENS=4096

# Temperature for LLM (0.0 = deterministic, 1.0 = creative)
LLM_TEMPERATURE=0.3

# -------------------------------------------
# Rate Limiting
# -------------------------------------------
# Maximum number of concurrent reviews
MAX_CONCURRENT_REVIEWS=5

# Timeout for a single review in seconds
REVIEW_TIMEOUT_SECONDS=300
